--- go1.13/src/go/scanner/scanner.go	2019-09-03 19:07:47.000000000 +0200
+++ scanner.go	2019-09-19 20:29:30.626331806 +0200
@@ -16,6 +16,8 @@
 	"strconv"
 	"unicode"
 	"unicode/utf8"
+
+	"github.com/truthtracer/gomacro/go/etoken"
 )
 
 // An ErrorHandler may be provided to Scanner.Init. If a syntax error is
@@ -31,12 +33,14 @@
 //
 type Scanner struct {
 	// immutable state
-	file *token.File  // source file handle
+	file *etoken.File // source file handle
 	dir  string       // directory portion of file.Name()
 	src  []byte       // source
 	err  ErrorHandler // error reporting; or nil
 	mode Mode         // scanning mode
 
+	macroChar rune // prefix of macro-related keywords and symbols ' ` , ,@
+
 	// scanning state
 	ch         rune // current character
 	offset     int  // character offset
@@ -119,7 +123,7 @@
 // Note that Init may call err if there is an error in the first character
 // of the file.
 //
-func (s *Scanner) Init(file *token.File, src []byte, err ErrorHandler, mode Mode) {
+func (s *Scanner) Init(file *etoken.File, src []byte, err ErrorHandler, mode Mode, macroChar rune) {
 	// Explicitly initialize all fields since a scanner may be reused.
 	if file.Size() != len(src) {
 		panic(fmt.Sprintf("file size (%d) does not match src len (%d)", file.Size(), len(src)))
@@ -129,6 +133,7 @@
 	s.src = src
 	s.err = err
 	s.mode = mode
+	s.macroChar = macroChar
 
 	s.ch = ' '
 	s.offset = 0
@@ -793,7 +798,7 @@
 		lit = s.scanIdentifier()
 		if len(lit) > 1 {
 			// keywords are longer than one letter - avoid lookup otherwise
-			tok = token.Lookup(lit)
+			tok = etoken.Lookup(lit)
 			switch tok {
 			case token.IDENT, token.BREAK, token.CONTINUE, token.FALLTHROUGH, token.RETURN:
 				insertSemi = true
@@ -874,8 +879,14 @@
 			}
 		case '*':
 			tok = s.switch2(token.MUL, token.MUL_ASSIGN)
-		case '/':
-			if s.ch == '/' || s.ch == '*' {
+		case '/', '#':
+			if ch == '/' && (s.ch == '/' || s.ch == '*') || ch == '#' && s.ch == '!' {
+				// accept both #! and // as line comments
+				// in this way, *.gomacro files can start with "#!/usr/bin/env gomacro"
+				// Unix-like systems will happily execute them directly
+				if s.ch == '!' {
+					s.ch = '/'
+				}
 				// comment
 				if s.insertSemi && s.findLineEnd() {
 					// reset position to the beginning of the comment
@@ -893,7 +904,15 @@
 				}
 				tok = token.COMMENT
 				lit = comment
+			} else if ch == '/' {
+				tok = s.switch2(token.QUO, token.QUO_ASSIGN)
+			} else if ch == '#' {
+				tok = etoken.HASH
 			} else {
+				s.error(s.file.Offset(pos), fmt.Sprintf("illegal character %#U", ch))
+				insertSemi = s.insertSemi // preserve insertSemi info
+				tok = token.ILLEGAL
+				lit = string(ch)
 				tok = s.switch2(token.QUO, token.QUO_ASSIGN)
 			}
 		case '%':
@@ -922,6 +941,35 @@
 			}
 		case '|':
 			tok = s.switch3(token.OR, token.OR_ASSIGN, '|', token.LOR)
+		case s.macroChar:
+			// patch: support macro, quote and friends. s.macroChar is configurable, default is '~'
+			// quote           macroChar '
+			// quasiquote      macroChar `
+			// unquote         macroChar ,
+			// unquote_splice  macroChar ,@
+			switch s.ch {
+			case '\'':
+				s.next()
+				tok = etoken.QUOTE
+			case '`', '"': // accept both ~` and ~" as ~quasiquote, because ~` confuses syntax hilighting in IDEs
+				s.next()
+				tok = etoken.QUASIQUOTE
+			case ',':
+				s.next()
+				if s.ch == '@' {
+					s.next()
+					tok = etoken.UNQUOTE_SPLICE
+				} else {
+					tok = etoken.UNQUOTE
+				}
+			default:
+				lit = s.scanIdentifier()
+				tok = etoken.LookupSpecial(lit)
+				if tok == token.ILLEGAL {
+					s.error(s.file.Offset(pos), fmt.Sprintf("expecting macro-related keyword after '%c', found '%c%s'", s.macroChar, s.macroChar, lit))
+					insertSemi = s.insertSemi // preserve insertSemi info
+				}
+			}
 		default:
 			// next reports unexpected BOMs - don't repeat
 			if ch != bom {
--- go1.13/src/go/scanner/scanner_test.go	2019-09-03 19:07:47.000000000 +0200
+++ scanner_test.go	2019-09-19 20:27:00.097093374 +0200
@@ -12,9 +12,13 @@
 	"runtime"
 	"strings"
 	"testing"
+
+	"github.com/truthtracer/gomacro/go/etoken"
 )
 
-var fset = token.NewFileSet()
+var fset = etoken.NewFileSet()
+
+const macroChar = '~'
 
 const /* class */ (
 	special = iota
@@ -233,7 +237,7 @@
 
 	// verify scan
 	var s Scanner
-	s.Init(fset.AddFile("", fset.Base(), len(source)), source, eh, ScanComments|dontInsertSemis)
+	s.Init(fset.AddFile("", fset.Base(), len(source), 0), source, eh, ScanComments|dontInsertSemis, macroChar)
 
 	// set up expected position
 	epos := token.Position{
@@ -336,15 +340,15 @@
 
 func checkSemi(t *testing.T, line string, mode Mode) {
 	var S Scanner
-	file := fset.AddFile("TestSemis", fset.Base(), len(line))
-	S.Init(file, []byte(line), nil, mode)
+	file := fset.AddFile("TestSemis", fset.Base(), len(line), 0)
+	S.Init(file, []byte(line), nil, mode, macroChar)
 	pos, tok, lit := S.Scan()
 	for tok != token.EOF {
 		if tok == token.ILLEGAL {
 			// the illegal token literal indicates what
 			// kind of semicolon literal to expect
 			semiLit := "\n"
-			if lit[0] == '#' {
+			if lit[0] == '@' {
 				semiLit = ";"
 			}
 			// next token must be a semicolon
@@ -368,11 +372,11 @@
 }
 
 var lines = []string{
-	// # indicates a semicolon present in the source
+	// @ indicates a semicolon present in the source
 	// $ indicates an automatically inserted semicolon
 	"",
-	"\ufeff#;", // first BOM is ignored
-	"#;",
+	"\ufeff@;", // first BOM is ignored
+	"@;",
 	"foo$\n",
 	"123$\n",
 	"1.2$\n",
@@ -433,7 +437,7 @@
 	")$\n",
 	"]$\n",
 	"}$\n",
-	"#;\n",
+	"@;\n",
 	":\n",
 
 	"break$\n",
@@ -576,8 +580,8 @@
 
 	// verify scan
 	var S Scanner
-	file := fset.AddFile(filename, fset.Base(), len(src))
-	S.Init(file, []byte(src), func(pos token.Position, msg string) { t.Error(Error{pos, msg}) }, dontInsertSemis)
+	file := fset.AddFile(filename, fset.Base(), len(src), 0)
+	S.Init(file, []byte(src), func(pos token.Position, msg string) { t.Error(Error{pos, msg}) }, dontInsertSemis, macroChar)
 	for _, s := range segments {
 		p, _, lit := S.Scan()
 		pos := file.Position(p)
@@ -615,7 +619,7 @@
 	// verify scan
 	var S Scanner
 	var s segment // current segment
-	file := fset.AddFile(filepath.Join("dir", "TestInvalidLineDirectives"), fset.Base(), len(src))
+	file := fset.AddFile(filepath.Join("dir", "TestInvalidLineDirectives"), fset.Base(), len(src), 0)
 	S.Init(file, []byte(src), func(pos token.Position, msg string) {
 		if msg != s.filename {
 			t.Errorf("got error %q; want %q", msg, s.filename)
@@ -623,7 +627,7 @@
 		if pos.Line != s.line || pos.Column != s.column {
 			t.Errorf("got position %d:%d; want %d:%d", pos.Line, pos.Column, s.line, s.column)
 		}
-	}, dontInsertSemis)
+	}, dontInsertSemis, macroChar)
 	for _, s = range invalidSegments {
 		S.Scan()
 	}
@@ -639,8 +643,8 @@
 
 	// 1st init
 	src1 := "if true { }"
-	f1 := fset.AddFile("src1", fset.Base(), len(src1))
-	s.Init(f1, []byte(src1), nil, dontInsertSemis)
+	f1 := fset.AddFile("src1", fset.Base(), len(src1), 0)
+	s.Init(f1, []byte(src1), nil, dontInsertSemis, macroChar)
 	if f1.Size() != len(src1) {
 		t.Errorf("bad file size: got %d, expected %d", f1.Size(), len(src1))
 	}
@@ -653,8 +657,8 @@
 
 	// 2nd init
 	src2 := "go true { ]"
-	f2 := fset.AddFile("src2", fset.Base(), len(src2))
-	s.Init(f2, []byte(src2), nil, dontInsertSemis)
+	f2 := fset.AddFile("src2", fset.Base(), len(src2), 0)
+	s.Init(f2, []byte(src2), nil, dontInsertSemis, macroChar)
 	if f2.Size() != len(src2) {
 		t.Errorf("bad file size: got %d, expected %d", f2.Size(), len(src2))
 	}
@@ -682,7 +686,7 @@
 	eh := func(pos token.Position, msg string) { list.Add(pos, msg) }
 
 	var s Scanner
-	s.Init(fset.AddFile("File1", fset.Base(), len(src)), []byte(src), eh, dontInsertSemis)
+	s.Init(fset.AddFile("File1", fset.Base(), len(src), 0), []byte(src), eh, dontInsertSemis, macroChar)
 	for {
 		if _, tok, _ := s.Scan(); tok == token.EOF {
 			break
@@ -725,7 +729,7 @@
 		h.msg = msg
 		h.pos = pos
 	}
-	s.Init(fset.AddFile("", fset.Base(), len(src)), []byte(src), eh, ScanComments|dontInsertSemis)
+	s.Init(fset.AddFile("", fset.Base(), len(src), 0), []byte(src), eh, ScanComments|dontInsertSemis, macroChar)
 	_, tok0, lit0 := s.Scan()
 	if tok0 != tok {
 		t.Errorf("%q: got %s, expected %s", src, tok0, tok)
@@ -756,7 +760,7 @@
 	err string
 }{
 	{"\a", token.ILLEGAL, 0, "", "illegal character U+0007"},
-	{`#`, token.ILLEGAL, 0, "", "illegal character U+0023 '#'"},
+	{`@`, token.ILLEGAL, 0, "", "illegal character U+0040 '@'"},
 	{`…`, token.ILLEGAL, 0, "", "illegal character U+2026 '…'"},
 	{"..", token.PERIOD, 0, "", ""}, // two periods, not invalid token (issue #28112)
 	{`' '`, token.CHAR, 0, `' '`, ""},
@@ -843,7 +847,7 @@
 		}
 	`
 	var s Scanner
-	s.Init(fset.AddFile("", fset.Base(), len(src)), []byte(src), nil, 0)
+	s.Init(fset.AddFile("", fset.Base(), len(src), 0), []byte(src), nil, 0, macroChar)
 	for {
 		pos, tok, lit := s.Scan()
 		class := tokenclass(tok)
@@ -860,7 +864,7 @@
 	const src = "... .. 0.. .." // make sure to have stand-alone ".." immediately before EOF to test EOF behavior
 	tokens := []token.Token{token.ELLIPSIS, token.PERIOD, token.PERIOD, token.FLOAT, token.PERIOD, token.PERIOD, token.PERIOD, token.EOF}
 	var s Scanner
-	s.Init(fset.AddFile("", fset.Base(), len(src)), []byte(src), nil, 0)
+	s.Init(fset.AddFile("", fset.Base(), len(src), 0), []byte(src), nil, 0, macroChar)
 	for _, want := range tokens {
 		pos, got, lit := s.Scan()
 		if got != want {
@@ -875,12 +879,12 @@
 
 func BenchmarkScan(b *testing.B) {
 	b.StopTimer()
-	fset := token.NewFileSet()
-	file := fset.AddFile("", fset.Base(), len(source))
+	fset := etoken.NewFileSet()
+	file := fset.AddFile("", fset.Base(), len(source), 0)
 	var s Scanner
 	b.StartTimer()
 	for i := 0; i < b.N; i++ {
-		s.Init(file, source, nil, ScanComments)
+		s.Init(file, source, nil, ScanComments, macroChar)
 		for {
 			_, tok, _ := s.Scan()
 			if tok == token.EOF {
@@ -897,13 +901,13 @@
 	if err != nil {
 		panic(err)
 	}
-	fset := token.NewFileSet()
-	file := fset.AddFile(filename, fset.Base(), len(src))
+	fset := etoken.NewFileSet()
+	file := fset.AddFile(filename, fset.Base(), len(src), 0)
 	b.SetBytes(int64(len(src)))
 	var s Scanner
 	b.StartTimer()
 	for i := 0; i < b.N; i++ {
-		s.Init(file, src, nil, ScanComments)
+		s.Init(file, src, nil, ScanComments, macroChar)
 		for {
 			_, tok, _ := s.Scan()
 			if tok == token.EOF {
@@ -1069,11 +1073,11 @@
 	} {
 		var s Scanner
 		var err string
-		s.Init(fset.AddFile("", fset.Base(), len(test.src)), []byte(test.src), func(_ token.Position, msg string) {
+		s.Init(fset.AddFile("", fset.Base(), len(test.src), 0), []byte(test.src), func(_ token.Position, msg string) {
 			if err == "" {
 				err = msg
 			}
-		}, 0)
+		}, 0, macroChar)
 		for i, want := range strings.Split(test.tokens, " ") {
 			err = ""
 			_, tok, lit := s.Scan()
